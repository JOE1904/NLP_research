{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># <center> **NLP CAC3 Project**\n",
    "### **Project Title :** A Document Read-Chat-Note Making Assistant\n",
    "**A joint initiative by: <br>\n",
    "Krish Goyal(21112015) and Joan Job(21112037)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Key Highlights, Features, Steps and Research Gaps to Understand:**\n",
    "##### **Features:** \n",
    "1. The applications supports <u>*.pdf*</u> and <u>*.txt*</u> file formats for document uploads.<br><hr>\n",
    "2. If not, the user has the liberty to copy-paste the required text into the text-box provided. <br><hr>\n",
    "3. The application then scans through the text provided, check for grammatical errors and corrects them <br>\n",
    "    if necessary. (If time permits us to do it.) <br><hr>\n",
    "4. All keywords present in the data will be highlighted/ underlined \n",
    "    (mostly Proper Nouns such as names of places, states, countries, unique personalities etc.)<br><hr>\n",
    "5. There is also an option for the user to chat with the extension for text summaries, word meanings, synonyms etc. <br><hr>\n",
    "6. The Notes file generated can be downloaded seperately as .txt or .pdf file for offline use (as proposed).<br><hr>\n",
    "\n",
    "##### **Basic Architecture Requirements:**  <u></u>\n",
    "1. PDF to Text File Conversion <br> \n",
    "2. Text Preprocessing <br>\n",
    "3. Wikipedia API/Library or Webscraping for extracting text for Named-Entities.\n",
    "4. Text Summarizing Model with the Metrics for Comparative Study for both:\n",
    "    - Named-Entities with and their introductory paragraphs.\n",
    "    - Also for the text document as a whole. \n",
    "    - Summary for Each Subheadings (If Possible.) <br>\n",
    "5. Name-Entity-Recognition(NER) Model with most apt results.<br>\n",
    "6. A Chatbot to chat with User and Understand User Inputs to the Above mentioned Functions.<br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References:\n",
    "1.\n",
    "1.\n",
    "1.\n",
    "1.\n",
    "1.\n",
    "1.\n",
    "1.\n",
    "1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. PDF to Text File Conversion and Cleaning/Formatting(Basic) <br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import re \n",
    "from datetime import datetime\n",
    "\n",
    "# Function to read PDF files and store the extracted text in a text file\n",
    "def read_pdf(file_path):\n",
    "    timestamp = datetime.now().strftime(\"Y%Y_M%m_D%dT_%H_%M_%S\") \n",
    "    cleaned_path = re.sub(r'[:.\\/\\\\*\\?\"<>|]', '_', file_path)\n",
    "    new_text_file_name =  f\"{cleaned_path}_output_{timestamp}.txt\"\n",
    "    with open(file_path, 'rb') as pdf_file:\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "        text = \"\"\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "\n",
    "        text_to_txt = clean_text(text)\n",
    "    try:\n",
    "        with open(new_text_file_name, 'w', encoding='utf-8') as file:\n",
    "            file.write(text_to_txt)\n",
    "        print(f\"Text has been successfully written to {new_text_file_name}\")\n",
    "        return new_text_file_name\n",
    "    except Exception as e:\n",
    "        print(f\"Error while writing to the file: {e}\")\n",
    "\n",
    "\n",
    "# Function to read text files and store the text in a variable\n",
    "def read_text(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as txt_file:\n",
    "            text = txt_file.read()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error while processing the text file: {e}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove line breaks and extra spaces\n",
    "    text = re.sub(r'\\n+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "\n",
    "    # Remove unwanted characters\n",
    "    text = re.sub(r'[^A-Za-z0-9.,?!()\\'\":;\\- ]', '', text)\n",
    "    \n",
    "    # Add missing spaces after punctuation marks\n",
    "    text = re.sub(r'([.,?!();:])', r'\\1 ', text)\n",
    "    \n",
    "    # Remove extra spaces after punctuation marks\n",
    "    text = re.sub(r' +([.,?!();:])', r'\\1', text)\n",
    "    \n",
    "    # Remove spaces before punctuation marks\n",
    "    text = re.sub(r' ([.,?!();:])', r'\\1', text)\n",
    "    \n",
    "    # Remove spaces before and after hyphens\n",
    "    text = re.sub(r' - ', ' -', text)\n",
    "    text = re.sub(r' -', '-', text)\n",
    "    text = re.sub(r'- ', '-', text)\n",
    "    return text\n",
    "\n",
    "# Function to identify and process the uploaded file\n",
    "def process_uploaded_file(uploaded_file_path):\n",
    "    if uploaded_file_path.endswith('.pdf'):\n",
    "        # It's a PDF, read and store the text in a text file\n",
    "        file_name = read_pdf(uploaded_file_path)\n",
    "        with open(file_name, 'r', encoding='utf-8') as txt_file:\n",
    "            text = txt_file.readlines()\n",
    "        return text\n",
    "\n",
    "    elif uploaded_file_path.endswith('.txt'):\n",
    "        # It's a text file, read the text directly into a variable\n",
    "        return read_text(uploaded_file_path)\n",
    "    else:\n",
    "        print(\"Unsupported file format. Please upload a PDF or a text file.\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def remove_special_characters(input_string):\n",
    "    # Remove special characters and brackets using regex\n",
    "    cleaned_string = re.sub(r'[^a-zA-Z0-9\\s]', '', input_string)\n",
    "\n",
    "    # Remove accents using Unicode normalization\n",
    "    cleaned_string = unicodedata.normalize('NFKD', cleaned_string).encode('ASCII', 'ignore').decode('utf-8')\n",
    "\n",
    "    return cleaned_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pegasus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.encoder.embed_positions.weight', 'model.decoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A new deep residual network, called Wide ResNet, has been developed.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, PegasusForConditionalGeneration\n",
    "\n",
    "model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/pegasus-xsum\")\n",
    "\n",
    "ARTICLE_TO_SUMMARIZE = ('''The biggest disadvantage of deep residual networks, according to some, is the feature reuse problem, in which some feature changes or blocks may contribute relatively little to learning. Wide ResNet was formed to solve this issue. The major learning potential of deep residual networks, according to Zagoruyko and Komodakis, is attributable to the residual units, whereas depth has a supplemental influence. ResNet was made wide rather than deep to take use of the residual blocks' strength''')\n",
    "inputs = tokenizer(ARTICLE_TO_SUMMARIZE, max_length=1024, return_tensors=\"pt\")\n",
    "\n",
    "# Generate Summary\n",
    "summary_ids = model.generate(inputs[\"input_ids\"])\n",
    "tokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.encoder.embed_positions.weight', 'model.decoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\COLLEGE DATA\\SEM V\\BDS573BL - Natural Language Processing\\NLP-Project\\NLP_research\\project.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/NLP_research/project.ipynb#X56sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Define your training dataset and training arguments\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/NLP_research/project.ipynb#X56sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Replace `train_dataset` and other placeholders with your actual data and arguments\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/NLP_research/project.ipynb#X56sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\u001b[39mNew York (CNN)When Liana Barrientos was 23 years old, she got married in Westchester County, New York.\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/NLP_research/project.ipynb#X56sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mA year later, she got married again in Westchester County, but to a different man and without divorcing her first husband.\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/NLP_research/project.ipynb#X56sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mOnly 18 days after that marriage, she got hitched yet again. Then, Barrientos declared \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mI do\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m five more times, sometimes only within two weeks of each other.\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/NLP_research/project.ipynb#X56sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mHer eighth husband, Rashid Rajput, was deported in 2006 to his native Pakistan after an investigation by the Joint Terrorism Task Force.\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/NLP_research/project.ipynb#X56sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mIf convicted, Barrientos faces up to four years in prison.  Her next court appearance is scheduled for May 18.\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/NLP_research/project.ipynb#X56sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m training_args \u001b[39m=\u001b[39m TrainingArguments(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/NLP_research/project.ipynb#X56sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     output_dir\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m./output\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/NLP_research/project.ipynb#X56sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     overwrite_output_dir\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/NLP_research/project.ipynb#X56sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     num_train_epochs\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/NLP_research/project.ipynb#X56sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     per_device_train_batch_size\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/NLP_research/project.ipynb#X56sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     save_steps\u001b[39m=\u001b[39;49m\u001b[39m5000\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/NLP_research/project.ipynb#X56sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/NLP_research/project.ipynb#X56sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# Create the trainer and fine-tune the model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/NLP_research/project.ipynb#X56sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/NLP_research/project.ipynb#X56sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/NLP_research/project.ipynb#X56sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/NLP_research/project.ipynb#X56sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     train_dataset\u001b[39m=\u001b[39mtrain_dataset\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/NLP_research/project.ipynb#X56sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m )\n",
      "File \u001b[1;32m<string>:115\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, sharded_ddp, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, include_inputs_for_metrics, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, dispatch_batches, include_tokens_per_second)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\goyal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\training_args.py:1436\u001b[0m, in \u001b[0;36mTrainingArguments.__post_init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1430\u001b[0m     \u001b[39mif\u001b[39;00m version\u001b[39m.\u001b[39mparse(version\u001b[39m.\u001b[39mparse(torch\u001b[39m.\u001b[39m__version__)\u001b[39m.\u001b[39mbase_version) \u001b[39m==\u001b[39m version\u001b[39m.\u001b[39mparse(\u001b[39m\"\u001b[39m\u001b[39m2.0.0\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp16:\n\u001b[0;32m   1431\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m--optim adamw_torch_fused with --fp16 requires PyTorch>2.0\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1433\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1434\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1435\u001b[0m     \u001b[39mand\u001b[39;00m is_torch_available()\n\u001b[1;32m-> 1436\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice\u001b[39m.\u001b[39mtype \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1437\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\u001b[39m.\u001b[39mtype \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1438\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\u001b[39m.\u001b[39mtype \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1439\u001b[0m     \u001b[39mand\u001b[39;00m (get_xla_device_type(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice) \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mGPU\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1440\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp16 \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp16_full_eval)\n\u001b[0;32m   1441\u001b[0m ):\n\u001b[0;32m   1442\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1443\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1444\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m (`--fp16_full_eval`) can only be used on CUDA or NPU devices or certain XPU devices (with IPEX).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1445\u001b[0m     )\n\u001b[0;32m   1447\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1448\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1449\u001b[0m     \u001b[39mand\u001b[39;00m is_torch_available()\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1456\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbf16 \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbf16_full_eval)\n\u001b[0;32m   1457\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\goyal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\training_args.py:1901\u001b[0m, in \u001b[0;36mTrainingArguments.device\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1897\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1898\u001b[0m \u001b[39mThe device used by this process.\u001b[39;00m\n\u001b[0;32m   1899\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1900\u001b[0m requires_backends(\u001b[39mself\u001b[39m, [\u001b[39m\"\u001b[39m\u001b[39mtorch\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m-> 1901\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup_devices\n",
      "File \u001b[1;32mc:\\Users\\goyal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\generic.py:54\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[1;34m(self, obj, objtype)\u001b[0m\n\u001b[0;32m     52\u001b[0m cached \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(obj, attr, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m     53\u001b[0m \u001b[39mif\u001b[39;00m cached \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m     cached \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfget(obj)\n\u001b[0;32m     55\u001b[0m     \u001b[39msetattr\u001b[39m(obj, attr, cached)\n\u001b[0;32m     56\u001b[0m \u001b[39mreturn\u001b[39;00m cached\n",
      "File \u001b[1;32mc:\\Users\\goyal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\training_args.py:1801\u001b[0m, in \u001b[0;36mTrainingArguments._setup_devices\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1799\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[0;32m   1800\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_accelerate_available(min_version\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m0.20.1\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1801\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m   1802\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUsing the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1803\u001b[0m         )\n\u001b[0;32m   1804\u001b[0m     AcceleratorState\u001b[39m.\u001b[39m_reset_state(reset_partial_state\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1805\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistributed_state \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Trainer, TrainingArguments\n",
    "\n",
    "# Load the tokenizer and model\n",
    "model_name = \"google/pegasus-xsum\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Define your training dataset and training arguments\n",
    "# Replace `train_dataset` and other placeholders with your actual data and arguments\n",
    "train_dataset = \"\"\"New York (CNN)When Liana Barrientos was 23 years old, she got married in Westchester County, New York.\n",
    "A year later, she got married again in Westchester County, but to a different man and without divorcing her first husband.\n",
    "Only 18 days after that marriage, she got hitched yet again. Then, Barrientos declared \"I do\" five more times, sometimes only within two weeks of each other.\n",
    "In 2010, she married once more, this time in the Bronx. In an application for a marriage license, she stated it was her \"first and only\" marriage.\n",
    "Barrientos, now 39, is facing two criminal counts of \"offering a false instrument for filing in the first degree,\" referring to her false statements on the\n",
    "2010 marriage license application, according to court documents.\n",
    "Prosecutors said the marriages were part of an immigration scam.\n",
    "On Friday, she pleaded not guilty at State Supreme Court in the Bronx, according to her attorney, Christopher Wright, who declined to comment further.\n",
    "After leaving court, Barrientos was arrested and charged with theft of service and criminal trespass for allegedly sneaking into the New York subway through an emergency exit, said Detective\n",
    "Annette Markowski, a police spokeswoman. In total, Barrientos has been married 10 times, with nine of her marriages occurring between 1999 and 2002.\n",
    "All occurred either in Westchester County, Long Island, New Jersey or the Bronx. She is believed to still be married to four men, and at one time, she was married to eight men at once, prosecutors say.\n",
    "Prosecutors said the immigration scam involved some of her husbands, who filed for permanent residence status shortly after the marriages.\n",
    "Any divorces happened only after such filings were approved. It was unclear whether any of the men will be prosecuted.\n",
    "The case was referred to the Bronx District Attorney\\'s Office by Immigration and Customs Enforcement and the Department of Homeland Security\\'s\n",
    "Investigation Division. Seven of the men are from so-called \"red-flagged\" countries, including Egypt, Turkey, Georgia, Pakistan and Mali.\n",
    "Her eighth husband, Rashid Rajput, was deported in 2006 to his native Pakistan after an investigation by the Joint Terrorism Task Force.\n",
    "If convicted, Barrientos faces up to four years in prison.  Her next court appearance is scheduled for May 18.\"\"\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./output\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    save_steps=5000\n",
    ")\n",
    "\n",
    "# Create the trainer and fine-tune the model\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.encoder.embed_positions.weight', 'model.decoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\goyal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3974: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
      "\n",
      "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
      "this:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "labels = tokenizer(text_target=tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\COLLEGE DATA\\SEM V\\BDS573BL - Natural Language Processing\\NLP-Project\\NLP_research\\project.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/NLP_research/project.ipynb#X55sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m PegasusTokenizer\u001b[39m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/NLP_research/project.ipynb#X55sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model \u001b[39m=\u001b[39m PegasusForConditionalGeneration\u001b[39m.\u001b[39mfrom_pretrained(model_name)\u001b[39m.\u001b[39mto(torch_device)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/NLP_research/project.ipynb#X55sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m batch \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39;49mprepare_seq2seq_batch(src_text, truncation\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, padding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlongest\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mto(torch_device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/NLP_research/project.ipynb#X55sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m translated \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mgenerate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mbatch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/NLP_research/project.ipynb#X55sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m tgt_text \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mbatch_decode(translated, skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\goyal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:789\u001b[0m, in \u001b[0;36mBatchEncoding.to\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    785\u001b[0m \u001b[39m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001b[39;00m\n\u001b[0;32m    786\u001b[0m \u001b[39m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001b[39;00m\n\u001b[0;32m    787\u001b[0m \u001b[39m# into a HalfTensor\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(device, \u001b[39mstr\u001b[39m) \u001b[39mor\u001b[39;00m is_torch_device(device) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(device, \u001b[39mint\u001b[39m):\n\u001b[1;32m--> 789\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m {k: v\u001b[39m.\u001b[39;49mto(device\u001b[39m=\u001b[39;49mdevice) \u001b[39mfor\u001b[39;49;00m k, v \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mitems()}\n\u001b[0;32m    790\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    791\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAttempting to cast a BatchEncoding to type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(device)\u001b[39m}\u001b[39;00m\u001b[39m. This is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\goyal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:789\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    785\u001b[0m \u001b[39m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001b[39;00m\n\u001b[0;32m    786\u001b[0m \u001b[39m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001b[39;00m\n\u001b[0;32m    787\u001b[0m \u001b[39m# into a HalfTensor\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(device, \u001b[39mstr\u001b[39m) \u001b[39mor\u001b[39;00m is_torch_device(device) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(device, \u001b[39mint\u001b[39m):\n\u001b[1;32m--> 789\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m {k: v\u001b[39m.\u001b[39;49mto(device\u001b[39m=\u001b[39mdevice) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m    790\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    791\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAttempting to cast a BatchEncoding to type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(device)\u001b[39m}\u001b[39;00m\u001b[39m. This is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "# from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "# import torch\n",
    "# src_text = [\n",
    "#     \"\"\" PG&E stated it scheduled the blackouts in response to forecasts for high winds amid dry conditions. The aim is to reduce the risk of wildfires. Nearly 800 thousand customers were scheduled to be affected by the shutoffs which were expected to last through at least midday tomorrow.\"\"\"\n",
    "# ]\n",
    "\n",
    "# model_name = 'google/pegasus-xsum'\n",
    "# torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "# model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
    "# batch = tokenizer.prepare_seq2seq_batch(src_text, truncation=True, padding='longest').to(torch_device)\n",
    "# translated = model.generate(**batch)\n",
    "# tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "# assert tgt_text[0] == \"California's largest electricity provider has turned off power to hundreds of thousands of customers.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facebook - BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c095be6d6cdc4c9a9f56b8f0c7dcb46b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b7bca10c5e4fe185d9e673191cd592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb1b360b489042a094fcf387a5dabca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e100fd60b1fb4b618ae06a8d7a3b3b03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc25241708cc4816945bd80bf1542121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'Liana Barrientos, 39, is charged with two counts of \"offering a false instrument for filing in the first degree\" In total, she has been married 10 times, with nine of her marriages occurring between 1999 and 2002. She is believed to still be married to four men.'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "ARTICLE = \"\"\" New York (CNN)When Liana Barrientos was 23 years old, she got married in Westchester County, New York.\n",
    "A year later, she got married again in Westchester County, but to a different man and without divorcing her first husband.\n",
    "Only 18 days after that marriage, she got hitched yet again. Then, Barrientos declared \"I do\" five more times, sometimes only within two weeks of each other.\n",
    "In 2010, she married once more, this time in the Bronx. In an application for a marriage license, she stated it was her \"first and only\" marriage.\n",
    "Barrientos, now 39, is facing two criminal counts of \"offering a false instrument for filing in the first degree,\" referring to her false statements on the\n",
    "2010 marriage license application, according to court documents.\n",
    "Prosecutors said the marriages were part of an immigration scam.\n",
    "On Friday, she pleaded not guilty at State Supreme Court in the Bronx, according to her attorney, Christopher Wright, who declined to comment further.\n",
    "After leaving court, Barrientos was arrested and charged with theft of service and criminal trespass for allegedly sneaking into the New York subway through an emergency exit, said Detective\n",
    "Annette Markowski, a police spokeswoman. In total, Barrientos has been married 10 times, with nine of her marriages occurring between 1999 and 2002.\n",
    "All occurred either in Westchester County, Long Island, New Jersey or the Bronx. She is believed to still be married to four men, and at one time, she was married to eight men at once, prosecutors say.\n",
    "Prosecutors said the immigration scam involved some of her husbands, who filed for permanent residence status shortly after the marriages.\n",
    "Any divorces happened only after such filings were approved. It was unclear whether any of the men will be prosecuted.\n",
    "The case was referred to the Bronx District Attorney\\'s Office by Immigration and Customs Enforcement and the Department of Homeland Security\\'s\n",
    "Investigation Division. Seven of the men are from so-called \"red-flagged\" countries, including Egypt, Turkey, Georgia, Pakistan and Mali.\n",
    "Her eighth husband, Rashid Rajput, was deported in 2006 to his native Pakistan after an investigation by the Joint Terrorism Task Force.\n",
    "If convicted, Barrientos faces up to four years in prison.  Her next court appearance is scheduled for May 18.\n",
    "\"\"\"\n",
    "print(summarizer(ARTICLE, max_length=130, min_length=30, do_sample=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08f8c03d38394a55bbecf07d471cc196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31e50bc25d9a414595aa4f935c632d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d2b01a89d184297867459c0e4a34a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/300 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63ab35536224c0abe1ec129ad907d9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10875899f7ab41508e85ce86357dced3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba0f21a6dc24d78b056f9fbd3b04c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \"Jeff wants to train a Transformers model on Amazon SageMaker. He can use the new Hugging Face Deep Learning Container. Jeff can find the documentation on Huggingface's blog.    .   The blog is available at: https://huggingface.co/blog/the-partnership-amazon-sagemaker-and-hugling-face.\"}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "summarizer = pipeline(\"summarization\", model=\"philschmid/bart-large-cnn-samsum\")\n",
    "\n",
    "conversation = '''Jeff: Can I train a 🤗 Transformers model on Amazon SageMaker? \n",
    "Philipp: Sure you can use the new Hugging Face Deep Learning Container. \n",
    "Jeff: ok.\n",
    "Jeff: and how can I get started? \n",
    "Jeff: where can I find documentation? \n",
    "Philipp: ok, ok you can find everything here. https://huggingface.co/blog/the-partnership-amazon-sagemaker-and-hugging-face                                           \n",
    "'''\n",
    "summarizer(conversation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67316dfe45954794956abbdb2b80c8f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7083952edb514b2a9e7965878e0c0126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/1.84G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ee831b78224ff8afa72431d0d2b028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/1.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d13624080bd42c88badd8da425b0ef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1ef995216244589fbc8af434c6c5bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a007a2055a8a4e1f9e145e0a852059be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "effe817896064f98941e909d8a189c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 256, but your input_length is only 5. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=2)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "hf_name = 'pszemraj/led-large-book-summary'\n",
    "\n",
    "summarizer = pipeline(\n",
    "    \"summarization\",\n",
    "    hf_name,\n",
    "    device=0 if torch.cuda.is_available() else -1,\n",
    ")\n",
    "wall_of_text = \"your words here\"\n",
    "\n",
    "result = summarizer(\n",
    "    wall_of_text,\n",
    "    min_length=16,\n",
    "    max_length=256,\n",
    "    no_repeat_ngram_size=3,\n",
    "    encoder_no_repeat_ngram_size=3,\n",
    "    repetition_penalty=3.5,\n",
    "    num_beams=4,\n",
    "    early_stopping=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T5F "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: torch in c:\\users\\goyal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\goyal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\goyal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\goyal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\goyal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\goyal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\goyal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\goyal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping c:\\Users\\goyal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn-0.12.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\goyal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn-0.12.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\goyal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn-0.12.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\goyal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn-0.12.2.dist-info due to invalid metadata entry 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\goyal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.1.99)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping c:\\Users\\goyal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn-0.12.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\goyal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn-0.12.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\goyal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn-0.12.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\goyal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn-0.12.2.dist-info due to invalid metadata entry 'name'\n"
     ]
    }
   ],
   "source": [
    "%pip install torch\n",
    "%pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_https://huggingface.co/sarakolding/daT5-summariser_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'T5ForConditionalGeneration' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\COLLEGE DATA\\SEM V\\BDS573BL - Natural Language Processing\\NLP-Project\\project.ipynb Cell 21\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/project.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Load pre-trained T5 model and tokenizer:\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/project.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mt5-large\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/project.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model \u001b[39m=\u001b[39m T5ForConditionalGeneration\u001b[39m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/project.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m T5Tokenizer\u001b[39m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/project.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m intro_text \u001b[39min\u001b[39;00m df[\u001b[39m\"\u001b[39m\u001b[39mIntro_text\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'T5ForConditionalGeneration' is not defined"
     ]
    }
   ],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "# from transformers import pipeline\n",
    "\n",
    "# # Load pre-trained T5 model and tokenizer:\n",
    "# model_name = \"t5-large\"\n",
    "# model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "# tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# for intro_text in df[\"Intro_text\"]:\n",
    "#   inputs = tokenizer.encode(\"summarize: \" + text_to_summarize, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "#   summary_ids = model.generate(inputs, max_length=120, min_length=150, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "\n",
    "#   # Decode and print the summary\n",
    "#   summary_tf_small = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "#   df[\"Summary_tf-small\"] = summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://keras.io/examples/nlp/t5_hf_summarization/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "830e1d91a9744196bda24380a22e2ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/892 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\goyal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\goyal\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f483e06122864ebaac48d84b0cc3fb9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/977M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd8775560d1249dd91289af4273dd3f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/419 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f1e855b86bd47aca90f319ebcf2ba9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/767k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "170c03ff0e344e43b3230cd62a1ef79d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.21M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22588a46132141bd930f71122f24f50d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"summarization\", model=\"sarakolding/daT5-summariser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_https://huggingface.co/aszfcxcgszdx/article-summarizer-t5-large?text=I+love+AutoTrain+%F0%9F%A4%97_   --- See this --- (best model in gaining all the validation scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/cu111/torch_stable.html\n",
      "Requirement already satisfied: torch in c:\\users\\goyal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\goyal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.15.2)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\goyal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\goyal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\goyal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\goyal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\goyal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\goyal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\goyal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: requests in c:\\users\\goyal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\goyal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (9.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\goyal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\goyal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchvision) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\goyal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchvision) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\goyal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchvision) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\goyal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\goyal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping C:\\Users\\goyal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn-0.12.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\goyal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn-0.12.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\goyal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn-0.12.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\goyal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn-0.12.2.dist-info due to invalid metadata entry 'name'\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio -f https://download.pytorch.org/whl/cu111/torch_stable.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cpu\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available:  False\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\COLLEGE DATA\\SEM V\\BDS573BL - Natural Language Processing\\NLP-Project\\project.ipynb Cell 28\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/project.ipynb#X52sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/project.ipynb#X52sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCuda available: \u001b[39m\u001b[39m\"\u001b[39m, torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available())\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/project.ipynb#X52sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDevice name:\u001b[39m\u001b[39m\"\u001b[39m, torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49mget_device_name())\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/project.ipynb#X52sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Step 2: Check Tensorflow\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/project.ipynb#X52sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclient\u001b[39;00m \u001b[39mimport\u001b[39;00m device_lib\n",
      "File \u001b[1;32mc:\\Users\\goyal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\cuda\\__init__.py:365\u001b[0m, in \u001b[0;36mget_device_name\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_device_name\u001b[39m(device: Optional[_device_t] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m    354\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Gets the name of a device.\u001b[39;00m\n\u001b[0;32m    355\u001b[0m \n\u001b[0;32m    356\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[39m        str: the name of the device\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 365\u001b[0m     \u001b[39mreturn\u001b[39;00m get_device_properties(device)\u001b[39m.\u001b[39mname\n",
      "File \u001b[1;32mc:\\Users\\goyal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\cuda\\__init__.py:395\u001b[0m, in \u001b[0;36mget_device_properties\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_device_properties\u001b[39m(device: _device_t) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m _CudaDeviceProperties:\n\u001b[0;32m    386\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Gets the properties of a device.\u001b[39;00m\n\u001b[0;32m    387\u001b[0m \n\u001b[0;32m    388\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[39m        _CudaDeviceProperties: the properties of the device\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 395\u001b[0m     _lazy_init()  \u001b[39m# will define _get_device_properties\u001b[39;00m\n\u001b[0;32m    396\u001b[0m     device \u001b[39m=\u001b[39m _get_device_index(device, optional\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    397\u001b[0m     \u001b[39mif\u001b[39;00m device \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m device \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m device_count():\n",
      "File \u001b[1;32mc:\\Users\\goyal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\cuda\\__init__.py:239\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    236\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    237\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    238\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m'\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 239\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    240\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    241\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[0;32m    242\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# Step 1: Check Pytorch (optional)\n",
    "import torch\n",
    "print(\"Cuda available: \", torch.cuda.is_available())\n",
    "print(\"Device name:\", torch.cuda.get_device_name())\n",
    "# Step 2: Check Tensorflow\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "# Step 3: Check Keras (optional)\n",
    "from keras import backend as K\n",
    "print(K.tensorflow_backend._get_available_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cpu\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "my_tensor = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32, device=\"cpu\")\n",
    "print(my_tensor)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"New York (CNN)When Liana Barrientos was 23 years old, she got married in Westchester County, New York.\n",
    "A year later, she got married again in Westchester County, but to a different man and without divorcing her first husband.\n",
    "Only 18 days after that marriage, she got hitched yet again. Then, Barrientos declared \"I do\" five more times, sometimes only within two weeks of each other.\n",
    "In 2010, she married once more, this time in the Bronx. In an application for a marriage license, she stated it was her \"first and only\" marriage.\n",
    "Barrientos, now 39, is facing two criminal counts of \"offering a false instrument for filing in the first degree,\" referring to her false statements on the\n",
    "2010 marriage license application, according to court documents.\n",
    "Prosecutors said the marriages were part of an immigration scam.\n",
    "On Friday, she pleaded not guilty at State Supreme Court in the Bronx, according to her attorney, Christopher Wright, who declined to comment further.\n",
    "After leaving court, Barrientos was arrested and charged with theft of service and criminal trespass for allegedly sneaking into the New York subway through an emergency exit, said Detective\n",
    "Annette Markowski, a police spokeswoman. In total, Barrientos has been married 10 times, with nine of her marriages occurring between 1999 and 2002.\n",
    "All occurred either in Westchester County, Long Island, New Jersey or the Bronx. She is believed to still be married to four men, and at one time, she was married to eight men at once, prosecutors say.\n",
    "Prosecutors said the immigration scam involved some of her husbands, who filed for permanent residence status shortly after the marriages.\n",
    "Any divorces happened only after such filings were approved. It was unclear whether any of the men will be prosecuted.\n",
    "The case was referred to the Bronx District Attorney\\'s Office by Immigration and Customs Enforcement and the Department of Homeland Security\\'s\n",
    "Investigation Division. Seven of the men are from so-called \"red-flagged\" countries, including Egypt, Turkey, Georgia, Pakistan and Mali.\n",
    "Her eighth husband, Rashid Rajput, was deported in 2006 to his native Pakistan after an investigation by the Joint Terrorism Task Force.\n",
    "If convicted, Barrientos faces up to four years in prison.  Her next court appearance is scheduled for May 18.\"\"\"\n",
    "paraphrase(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\COLLEGE DATA\\SEM V\\BDS573BL - Natural Language Processing\\NLP-Project\\project.ipynb Cell 31\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/project.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Example code to move a tensor to the GPU\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/project.ipynb#X44sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m tensor_on_cpu \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/project.ipynb#X44sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m tensor_on_gpu \u001b[39m=\u001b[39m tensor_on_cpu\u001b[39m.\u001b[39;49mto(\u001b[39m'\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\goyal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\cuda\\__init__.py:239\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    236\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    237\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    238\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m'\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 239\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    240\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    241\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[0;32m    242\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# Example code to move a tensor to the GPU\n",
    "tensor_on_cpu = torch.randn(3, 3)\n",
    "tensor_on_gpu = tensor_on_cpu.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'httpcore' has no attribute 'NetworkBackend'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\COLLEGE DATA\\SEM V\\BDS573BL - Natural Language Processing\\NLP-Project\\project.ipynb Cell 36\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/project.ipynb#X50sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mvalidate_email\u001b[39;00m \u001b[39mimport\u001b[39;00m validate_email\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/COLLEGE%20DATA/SEM%20V/BDS573BL%20-%20Natural%20Language%20Processing/NLP-Project/project.ipynb#X50sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m is_valid \u001b[39m=\u001b[39m validate_email(email_address\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvt@alliswell.in\u001b[39m\u001b[39m'\u001b[39m, check_regex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, check_mx\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, from_address\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcireta7980@othao.com\u001b[39m\u001b[39m'\u001b[39m, helo_host\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmy.host.name\u001b[39m\u001b[39m'\u001b[39m, smtp_timeout\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, dns_timeout\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, use_blacklist\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, debug\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\goyal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\validate_email\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mvalidate_email\u001b[39;00m \u001b[39mimport\u001b[39;00m validate_email, validate_email_or_fail  \u001b[39m# NOQA\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\goyal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\validate_email\\validate_email.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mssl\u001b[39;00m \u001b[39mimport\u001b[39;00m SSLContext\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Optional\n\u001b[1;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdns_check\u001b[39;00m \u001b[39mimport\u001b[39;00m dns_check\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdomainlist_check\u001b[39;00m \u001b[39mimport\u001b[39;00m domainlist_check\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39memail_address\u001b[39;00m \u001b[39mimport\u001b[39;00m EmailAddress\n",
      "File \u001b[1;32mc:\\Users\\goyal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\validate_email\\dns_check.py:4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdns\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrdatatype\u001b[39;00m \u001b[39mimport\u001b[39;00m MX \u001b[39mas\u001b[39;00m rdtype_mx\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdns\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrdtypes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mANY\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mMX\u001b[39;00m \u001b[39mimport\u001b[39;00m MX\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdns\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mresolver\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      5\u001b[0m     NXDOMAIN, YXDOMAIN, Answer, NoAnswer, NoNameservers, resolve)\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconstants\u001b[39;00m \u001b[39mimport\u001b[39;00m HOST_REGEX\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39memail_address\u001b[39;00m \u001b[39mimport\u001b[39;00m EmailAddress\n",
      "File \u001b[1;32mc:\\Users\\goyal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dns\\resolver.py:30\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any, Dict, Iterator, List, Optional, Sequence, Tuple, Union\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39murllib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparse\u001b[39;00m \u001b[39mimport\u001b[39;00m urlparse\n\u001b[1;32m---> 30\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdns\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_ddr\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdns\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39medns\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdns\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexception\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\goyal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dns\\_ddr.py:12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdns\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minet\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdns\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mname\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdns\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnameserver\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdns\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mquery\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdns\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrdtypes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msvcbbase\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\goyal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dns\\nameserver.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39murllib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparse\u001b[39;00m \u001b[39mimport\u001b[39;00m urlparse\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdns\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39masyncbackend\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdns\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39masyncquery\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdns\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minet\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdns\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmessage\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\goyal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dns\\asyncquery.py:38\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdns\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransaction\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdns\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_asyncbackend\u001b[39;00m \u001b[39mimport\u001b[39;00m NullContext\n\u001b[1;32m---> 38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdns\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mquery\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     39\u001b[0m     BadResponse,\n\u001b[0;32m     40\u001b[0m     NoDOH,\n\u001b[0;32m     41\u001b[0m     NoDOQ,\n\u001b[0;32m     42\u001b[0m     UDPMode,\n\u001b[0;32m     43\u001b[0m     _compute_times,\n\u001b[0;32m     44\u001b[0m     _have_http2,\n\u001b[0;32m     45\u001b[0m     _matches_destination,\n\u001b[0;32m     46\u001b[0m     _remaining,\n\u001b[0;32m     47\u001b[0m     have_doh,\n\u001b[0;32m     48\u001b[0m     ssl,\n\u001b[0;32m     49\u001b[0m )\n\u001b[0;32m     51\u001b[0m \u001b[39mif\u001b[39;00m have_doh:\n\u001b[0;32m     52\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mhttpx\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\goyal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dns\\query.py:67\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mhttpcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_backends\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msync\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mhttpx\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m _CoreNetworkBackend \u001b[39m=\u001b[39m httpcore\u001b[39m.\u001b[39;49mNetworkBackend\n\u001b[0;32m     68\u001b[0m _CoreSyncStream \u001b[39m=\u001b[39m httpcore\u001b[39m.\u001b[39m_backends\u001b[39m.\u001b[39msync\u001b[39m.\u001b[39mSyncStream\n\u001b[0;32m     70\u001b[0m _have_httpx \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'httpcore' has no attribute 'NetworkBackend'"
     ]
    }
   ],
   "source": [
    "from validate_email import validate_email\n",
    "is_valid = validate_email(email_address='vt@alliswell.in', check_regex=True, check_mx=True, from_address='cireta7980@othao.com', helo_host='my.host.name', smtp_timeout=10, dns_timeout=10, use_blacklist=True, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%load_ext_cudf.pandas` not found.\n"
     ]
    }
   ],
   "source": [
    "%load_ext_cudf.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = \"\"\"New York (CNN)When Liana Barrientos was 23 years old, she got married in Westchester County, New York.\n",
    "A year later, she got married again in Westchester County, but to a different man and without divorcing her first husband.\n",
    "Only 18 days after that marriage, she got hitched yet again. Then, Barrientos declared \"I do\" five more times, sometimes only within two weeks of each other.\n",
    "In 2010, she married once more, this time in the Bronx. In an application for a marriage license, she stated it was her \"first and only\" marriage.\n",
    "Barrientos, now 39, is facing two criminal counts of \"offering a false instrument for filing in the first degree,\" referring to her false statements on the\n",
    "2010 marriage license application, according to court documents.\n",
    "Prosecutors said the marriages were part of an immigration scam.\n",
    "On Friday, she pleaded not guilty at State Supreme Court in the Bronx, according to her attorney, Christopher Wright, who declined to comment further.\n",
    "After leaving court, Barrientos was arrested and charged with theft of service and criminal trespass for allegedly sneaking into the New York subway through an emergency exit, said Detective\n",
    "Annette Markowski, a police spokeswoman. In total, Barrientos has been married 10 times, with nine of her marriages occurring between 1999 and 2002.\n",
    "All occurred either in Westchester County, Long Island, New Jersey or the Bronx. She is believed to still be married to four men, and at one time, she was married to eight men at once, prosecutors say.\n",
    "Prosecutors said the immigration scam involved some of her husbands, who filed for permanent residence status shortly after the marriages.\n",
    "Any divorces happened only after such filings were approved. It was unclear whether any of the men will be prosecuted.\n",
    "The case was referred to the Bronx District Attorney\\'s Office by Immigration and Customs Enforcement and the Department of Homeland Security\\'s\n",
    "Investigation Division. Seven of the men are from so-called \"red-flagged\" countries, including Egypt, Turkey, Georgia, Pakistan and Mali.\n",
    "Her eighth husband, Rashid Rajput, was deported in 2006 to his native Pakistan after an investigation by the Joint Terrorism Task Force.\n",
    "If convicted, Barrientos faces up to four years in prison.  Her next court appearance is scheduled for May 18\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". **Summary** Liana Barrientos, 39, of New York, is facing two criminal counts of \"offering a false instrument for filing in the first degree\" for allegedly lying on a 2010 marriage license application.\n",
      "Prosecutors allege that Barrientos married 10 times between 1999 and 2002, sometimes to multiple men at once, in an immigration scam.\n",
      "She is believed to still be married to four men, and at one time, she was married to eight men at once.\n",
      "Seven of the men are from so-called \"red-flagged\" countries, including Egypt, Turkey, Georgia, Pakistan and Mali.\n",
      "Barrientos' next court appearance is scheduled for May 18.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "At the command line, only need to run once to install the package via pip:\n",
    "\n",
    "$ pip install google-generativeai\n",
    "\"\"\"\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyBeKXOpP1-_Uuxl8BseTdR19uvlAnIbGlo\")\n",
    "\n",
    "defaults = {\n",
    "  'model': 'models/text-bison-001',\n",
    "  'temperature': 0.6,\n",
    "  'candidate_count': 1,\n",
    "  'top_k': 40,\n",
    "  'top_p': 0.95,\n",
    "  'max_output_tokens': 1024,\n",
    "  'stop_sequences': [],\n",
    "  'safety_settings': [{\"category\":\"HARM_CATEGORY_DEROGATORY\",\"threshold\":1},{\"category\":\"HARM_CATEGORY_TOXICITY\",\"threshold\":1},{\"category\":\"HARM_CATEGORY_VIOLENCE\",\"threshold\":2},{\"category\":\"HARM_CATEGORY_SEXUAL\",\"threshold\":2},{\"category\":\"HARM_CATEGORY_MEDICAL\",\"threshold\":2},{\"category\":\"HARM_CATEGORY_DANGEROUS\",\"threshold\":2}],\n",
    "}\n",
    "\n",
    "prompt = f\"\"\"Summarize this paragraph and detail some relevant context.\n",
    "\n",
    "Text: \"{text_input}\"\"\"\n",
    "\n",
    "response = genai.generate_text(\n",
    "  **defaults,\n",
    "  prompt=prompt\n",
    ")\n",
    "\n",
    "print(response.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(request):\n",
    "    text_input = request.POST.get('text_input', '')\n",
    "\n",
    "    defaults = {\n",
    "        'model': 'models/text-bison-001',\n",
    "        'temperature': 0.6,\n",
    "        'candidate_count': 1,\n",
    "        'top_k': 40,\n",
    "        'top_p': 0.95,\n",
    "        'max_output_tokens': 1024,\n",
    "        'stop_sequences': [],\n",
    "        'safety_settings': [\n",
    "            {\"category\": \"HARM_CATEGORY_DEROGATORY\", \"threshold\": 1},\n",
    "            {\"category\": \"HARM_CATEGORY_TOXICITY\", \"threshold\": 1},\n",
    "            {\"category\": \"HARM_CATEGORY_VIOLENCE\", \"threshold\": 2},\n",
    "            {\"category\": \"HARM_CATEGORY_SEXUAL\", \"threshold\": 2},\n",
    "            {\"category\": \"HARM_CATEGORY_MEDICAL\", \"threshold\": 2},\n",
    "            {\"category\": \"HARM_CATEGORY_DANGEROUS\", \"threshold\": 2},\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    prompt = f\"\"\"Summarize this paragraph and detail some relevant context.\n",
    "      Text: {text_input}\"\"\"\n",
    "\n",
    "    # Define response after the genai.generate_text call\n",
    "    response = genai.generate_text(\n",
    "        **defaults,\n",
    "        prompt=prompt\n",
    "    )\n",
    "\n",
    "    summary = response.result\n",
    "\n",
    "    content = {'summary': summary}\n",
    "    return render(request, 'summary.html', content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
